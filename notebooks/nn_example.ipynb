{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from models.neural_networks import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 784)\n",
      "(500, 10)\n"
     ]
    }
   ],
   "source": [
    "data_file = pd.read_csv(\"../data/cnn/mnist_train.csv\", header=None)\n",
    "x_data = []\n",
    "y_data = []\n",
    "for line_number in range(len(data_file)):\n",
    "    line = data_file.iloc[line_number, :]\n",
    "    image = np.array(line.iloc[1:]) / 255.\n",
    "    label = np.zeros(10)\n",
    "    label[int(line.iloc[0])] = 1\n",
    "    y_data.append(label)\n",
    "    x_data.append(image)\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "\n",
    "\n",
    "idx = np.random.permutation(len(x_data))[:5000]\n",
    "x_data = x_data[idx]\n",
    "y_data = y_data[idx]\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_data = x_data.reshape([len(x_data), 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 134826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:08<00:24,  4.12s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-fb01048d2ed7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[0mt1\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf'Number of parameters: {cnn.get_number_of_parameters()}'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m \u001B[0mcosts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlearn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mEPOCHS\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m64\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m \u001B[0mt2\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'time='\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mt2\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mt1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\mllab_library\\models\\neural_networks.py\u001B[0m in \u001B[0;36mlearn\u001B[1;34m(self, x, y, epochs, batch_size)\u001B[0m\n\u001B[0;32m    441\u001B[0m                     \u001B[1;32mfor\u001B[0m \u001B[0melement\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    442\u001B[0m                         \u001B[0mweight_sums\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mactivations\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0matleast_3d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0melement\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 443\u001B[1;33m                         \u001B[0mgradients\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradients_bias\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_back_propagate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mweight_sums\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mactivations\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0melement\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    444\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    445\u001B[0m                         \u001B[1;32mif\u001B[0m \u001B[0melement\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\mllab_library\\models\\neural_networks.py\u001B[0m in \u001B[0;36m_back_propagate\u001B[1;34m(self, weight_sums, activations, y)\u001B[0m\n\u001B[0;32m    389\u001B[0m             \u001B[0mlayer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    390\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlayer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mLinearLayer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mConvolutionalLayer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 391\u001B[1;33m                 \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompute_gradients\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdelta\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mactivations\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    392\u001B[0m                 \u001B[0mgradients\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    393\u001B[0m                 \u001B[0mgradients_bias\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\mllab_library\\models\\neural_networks.py\u001B[0m in \u001B[0;36mcompute_gradients\u001B[1;34m(self, delta, activation)\u001B[0m\n\u001B[0;32m     82\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mcompute_gradients\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdelta\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mactivation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     83\u001B[0m         \u001B[0mgradients\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mouter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdelta\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mactivation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 84\u001B[1;33m         \u001B[0mgradients\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgradients\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgradients_range\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgradients_range\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     85\u001B[0m         \u001B[0mgradients_bias\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdelta\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     86\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mclip\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32mE:\\miniconda3\\envs\\main\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001B[0m in \u001B[0;36mclip\u001B[1;34m(a, a_min, a_max, out, **kwargs)\u001B[0m\n\u001B[0;32m   2113\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2114\u001B[0m     \"\"\"\n\u001B[1;32m-> 2115\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_wrapfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'clip'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ma_min\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ma_max\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2116\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2117\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\miniconda3\\envs\\main\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001B[0m in \u001B[0;36m_wrapfunc\u001B[1;34m(obj, method, *args, **kwds)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     56\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 57\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mbound\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     58\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m         \u001B[1;31m# A TypeError occurs if the object does have such a method in its\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\miniconda3\\envs\\main\\lib\\site-packages\\numpy\\core\\_methods.py\u001B[0m in \u001B[0;36m_clip\u001B[1;34m(a, min, max, out, casting, **kwargs)\u001B[0m\n\u001B[0;32m    158\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    159\u001B[0m         return _clip_dep_invoke_with_casting(\n\u001B[1;32m--> 160\u001B[1;33m             um.clip, a, min, max, out=out, casting=casting, **kwargs)\n\u001B[0m\u001B[0;32m    161\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0m_mean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwhere\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\miniconda3\\envs\\main\\lib\\site-packages\\numpy\\core\\_methods.py\u001B[0m in \u001B[0;36m_clip_dep_invoke_with_casting\u001B[1;34m(ufunc, out, casting, *args, **kwargs)\u001B[0m\n\u001B[0;32m    111\u001B[0m     \u001B[1;31m# try to deal with broken casting rules\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 113\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mufunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    114\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0m_exceptions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_UFuncOutputCastingError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    115\u001B[0m         \u001B[1;31m# Numpy 1.17.0, 2019-02-24\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "## import your own implementation of softmax\n",
    "from scipy.special import softmax\n",
    "\n",
    "LEARNING_RATE = 0.1\n",
    "LAMBDA = 0.01\n",
    "EPOCHS = 50\n",
    "\n",
    "class Softmax(ActivationFunctionsForNN.BaseActivationFunctionForNN):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        return softmax(x)\n",
    "\n",
    "    def backward(self, x):\n",
    "        return x\n",
    "\n",
    "cnn = NeuralNetworkModel()\n",
    "\n",
    "layer1 = ConvolutionalLayer(kernel_size=3, padding=0, stride=1, input_channels=1, output_channels=10,\n",
    "            learning_rate=LEARNING_RATE, lambda_regularization=LAMBDA)  # -> 26x26x10\n",
    "layer2=PoolingLayer(stride=2, use_mean_pooling=True)  # -> 13x13x10\n",
    "layer3 = ConvolutionalLayer(kernel_size=5, padding=0, stride=1, input_channels=10, output_channels=16,\n",
    "            learning_rate=LEARNING_RATE, lambda_regularization=LAMBDA)  # -> 9x9x16\n",
    "layer4 = FlattenLayer() # size is automatically calculated -> mx1296\n",
    "layer5 = LinearLayer(input_shape=1296, output_shape=100,\n",
    "            learning_rate=LEARNING_RATE, lambda_regularization=LAMBDA) # -> mx100\n",
    "layer6 = LinearLayer(input_shape=100, output_shape=10,\n",
    "            learning_rate=LEARNING_RATE/10, activation_function=Softmax(),\n",
    "                     lambda_regularization=LAMBDA)  # -> mx10\n",
    "\n",
    "cnn.add_layer(layer1)\n",
    "cnn.add_layer(layer2)\n",
    "cnn.add_layer(layer3)\n",
    "cnn.add_layer(layer4)\n",
    "cnn.add_layer(layer5)\n",
    "cnn.add_layer(layer6)\n",
    "\n",
    "#cnn.loadWeights('cnn_weights.npz')\n",
    "\n",
    "import time\n",
    "t1=time.time()\n",
    "print(f'Number of parameters: {cnn.get_number_of_parameters()}')\n",
    "costs = cnn.learn(x_data, y_data, EPOCHS, 64)\n",
    "t2=time.time()\n",
    "print('time=',t2-t1)\n",
    "\n",
    "#cnn.saveWeights('cnn_weights.npz')\n",
    "\n",
    "n_train = x_data.shape[0]\n",
    "n_correct = 0\n",
    "for i in range(n_train):\n",
    "    xi = x_data[i]\n",
    "    yi = y_data[i]\n",
    "    yi = np.argmax(yi)\n",
    "    yhati = cnn.infer(xi)\n",
    "    yhati = np.argmax(yhati)\n",
    "    #print('i =', i, 'yi =', yi, 'yhati =', yhati)\n",
    "    if yhati == yi:\n",
    "        n_correct += 1\n",
    "\n",
    "print('n_correct =', n_correct, 'rate =', n_correct/n_train)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "figure = plt.figure(figsize=(12, 10), dpi=100)\n",
    "ax = figure.add_subplot(111)\n",
    "ax.plot(costs)\n",
    "figure.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}